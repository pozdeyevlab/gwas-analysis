import csv
from itertools import dropwhile
from pathlib import Path
from typing import (Dict, Iterable, List, NamedTuple, Optional, Set, Tuple,
                    Union)

import attr
import polars as pl
import sys

################################################################################
# Set Up
################################################################################
# Grab the location of various things from the config

map_file: Path      = Path(config["map_file"])
out_dir: Path       = Path(config["out_dir"])
rsid_map: Path      = Path(config["rsid_map"])
validation_bim_prefix = Path(config["validation_bim_prefix"])


# Create class to organize inputs and outputs
@attr.s(frozen=True, auto_attribs=True, kw_only=True)
class Output:
    """Represents all necessary meta data for each biobank gwas"""
    output_path_prscs: str
    output_prefix_prscs: str
    sst: str
    sst_raw: str
    n_gwas: int
    ld_ref: str


outputs: Dict[str, Output] = dict()

prscs_output = f"{out_dir}/{phenotype}/{phenotype}_prscs_results.tsv"
prscs_prefix = f"{out_dir}/{phenotype}/{phenotype}"

# Read map_df into pandas df
map_df: pd.DataFrame = pd.read_csv(map_file, sep="\t")

for index, row in map_df.iterrows():
    phenotype = row['phenotype']
    prscs_output = f"{out_dir}/{phenotype}/{phenotype}_prscs_results.tsv"
    prscs_prefix = f"{out_dir}/{phenotype}/{phenotype}"
    #plink_output = f"{out_dir}/{phenotype}/{phenotype}/plink"
    outputs[phenotype] = Output(
        output_path_prscs = prscs_output,
        output_prefix_prscs=prscs_prefix,
        sst=f'{out_dir}/prscs_analysis/{phenotype}.sst',
        sst_raw=row['input_file'],
        n_gwas=row['n_gwas'],
        ld_ref=row['ld_ref'])

print([f'{key}' for key, value in outputs.items()])
################################################################################
# Directives
################################################################################
onerror:
    """Code that gets called  if / when the snakemake pipeline exits with an error.
    The `log` variable contains a path to the snakemake log file which can be parsed
    for more information. Summarizes information on failed jobs and writes it to the
    output.
    """
    try:
        path = Path(log)
        RULE_PREFIX = "Error in rule "
        LOG_PREFIX = "    log: "
        CMD_PREFIX = "Command "

        with path.open("r") as fh:
            lines: Iterable[str] = fh.readlines()

        while lines:
            lines = list(dropwhile(lambda l: not l.startswith(RULE_PREFIX), lines))
            if lines:
                rule_name = lines[0].rstrip()[len(RULE_PREFIX) : -1]
                lines = dropwhile(lambda l: not l.startswith(LOG_PREFIX), lines)
                log_path = Path(next(lines).rstrip()[len(LOG_PREFIX) :].split()[0])

                print(f"========== Start of Error Info for {rule_name} ==========")
                print(f"Failed rule: {rule_name}")
                print(f"Contents of log file: {log_path}")
                with log_path.open("r") as fh:
                    for line in fh.readlines():
                        print(f"    {line.rstrip()}")
                print(f"=========== End of Error Info for {rule_name} ===========")
    except Exception as ex:
        print("################################################")
        print("Exception raised in snakemake onerror handler.")
        print(str(ex))
        print("################################################")


################################################################################
# Beginning of rule declarations
################################################################################
rule all:
    """
    Default rule that is executed when snakemake runs.  The 'inputs' here list the set of files
    that the pipeline will generate by default if a specific list isn't provided.
    """
    input:
        set([f'{value.sst}' for value in outputs.values()]),
        [f'{out_dir}/{phenotype}/{phenotype}_prscs_results.tsv' for phenotype in outputs],
	    [f'{out_dir}/{phenotype}/{phenotype}_prscs_results_lifted.tsv' for phenotype in outputs]


rule prep_input_files:
    input:
        sst_file = lambda wc: outputs[wc.phenotype].input_file,
        rsid_map = rsid_map
    output:
        sst_output = f'{out_dir}/prscs_analysis/{phenotype}.sst',
    shell:
        "python modules/make_input_files.py "
        "--meta-results-file {input.sst_file} "
        "--rsid-file {input.rsid_map} "
        "--output-sst {output.sst_output}"


rule run_prscs:
    params:
        n_gwas = lambda wc: outputs[wc.phenotype].n_gwas,
        prscs_prefix = lambda wc: outputs[wc.phenotype].output_prefix_prscs,
        ref_dir = lambda wc: outputs[wc.phenotype].ld_ref,
        validation_bim_prefix = validation_bim_prefix
    input:
        sst_file = lambda wc: outputs[wc.phenotype].sst,
    output:
        out_file = "{out_dir}/{phenotype}/{phenotype}_prscs_results.tsv"
    log:
        "{out_dir}/{phenotype}/{phenotype}_prscs_results.log"
    shell:
        "python PRScs/PRScs.py "
        "--ref_dir={params.ref_dir} "
        "--bim_prefix={params.validation_bim_prefix} "
        "--sst_file={input.sst_file} "
        "--n_gwas={params.n_gwas} "
        "--chrom=1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23 "
        "--phi=1e-4 "
        "--out_dir={params.prscs_prefix} && "
        "cat {params.prscs_prefix}*.txt > {output.out_file}"


rule lift_results:
    input:
        prscs_results = f"{out_dir}/{phenotype}/{phenotype}_prscs_results.tsv",
    params:
        bim_file = f'{validation_bim_prefix}.bim'
    output:
        f"{out_dir}/{phenotype}/{phenotype}_prscs_results_lifted.tsv"
    log:
        f"{out_dir}/{phenotype}/{phenotype}_prscs_results_lifted.log"
    shell:
        "python modules/lift.py "
        "-p {input.prscs_results} "
        "-b {params.bim_file} "
        "-o {output} &> {log}"
